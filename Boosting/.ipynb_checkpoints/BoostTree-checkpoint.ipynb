{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归方法\n",
    "\n",
    "跟adaboost方法不同之处：\n",
    "1. 提升树每个分类器学习的是之前所有分类器的残差\n",
    "2. 提升树的组合方式是累加，没有权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "split_dataset\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    res: the fitting residual of the model\n",
    "    split: split point\n",
    "'''\n",
    "def split_dataset(dataset, res, split):\n",
    "    out = np.zeros_like(res)\n",
    "    \n",
    "    sub1 = dataset < split\n",
    "    sub2 = dataset >= split\n",
    "    \n",
    "    c1 = np.mean(res[sub1])\n",
    "    c2 = np.mean(res[sub2])\n",
    "    \n",
    "    out[sub1] = c1\n",
    "    out[sub2] = c2\n",
    "    \n",
    "    return out, c1, c2\n",
    "\n",
    "'''\n",
    "generate stump, iterate all feature and split point to get a best feature split value\n",
    "parameter:\n",
    "    \n",
    "'''\n",
    "def generate_stump(dataset, labels):\n",
    "    n, m = dataset.shape\n",
    "    \n",
    "    best_index = 0\n",
    "    best_split = 0\n",
    "    best_cs = [0, 0]\n",
    "    best_res = np.inf\n",
    "    max_step = 10\n",
    "    model = []\n",
    "    for i in range(m):\n",
    "        vec = dataset[:, i]\n",
    "        min_v, max_v = vec.min(), vec.max()\n",
    "        stride = (max_v - min_v)/max_step\n",
    "        for j in range(-1, max_step+1):\n",
    "            split_point = min_v + j*stride\n",
    "            pred, c1, c2 = split_dataset(vec, labels, split_point)\n",
    "            res = labels - pred\n",
    "            norm_res = np.sum(res*res)\n",
    "            # print(\">>> value {} cs {} error {}\".format(split_point, (c1, c2), norm_res))\n",
    "            if norm_res < best_res:\n",
    "                best_res = norm_res\n",
    "                best_index = i\n",
    "                best_split = split_point\n",
    "                best_cs = [c1, c2]\n",
    "    return best_index, best_split, best_cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测函数\n",
    "\n",
    "1. 给定模型\n",
    "2. 累加每一个子分类器回归的值得到最终的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predict: predict the value of regress\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    model: model\n",
    "'''\n",
    "def predict(dataset, models):\n",
    "    n, m = dataset.shape\n",
    "    \n",
    "    out = np.zeros(n)\n",
    "    for m in models:\n",
    "        idx, value, cs = m\n",
    "        c1, c2 = cs\n",
    "        out[dataset[:, idx] < value] += c1\n",
    "        out[dataset[:, idx] >= value] += c2\n",
    "    \n",
    "    return out\n",
    "\n",
    "'''\n",
    "training: train the dataset\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    labels: labels\n",
    "    cnt: number of subclassifier\n",
    "    toler: terminate condition\n",
    "'''\n",
    "def train(dataset, labels, cnt, toler):\n",
    "    n, m = dataset.shape\n",
    "    \n",
    "    res = labels.copy()\n",
    "    models = []\n",
    "    for i in range(cnt):\n",
    "        index, split, cs = generate_stump(dataset, res)\n",
    "        print(\"index {} value {} cs ({}, {})\".format(index, split, cs[0], cs[1]))\n",
    "        models.append([index, split, cs])\n",
    "        pred = predict(dataset, models)\n",
    "        res = labels - pred\n",
    "        res_v = np.sum(res*res)\n",
    "        print(\"new res: \", res_v)\n",
    "        if res_v < toler:\n",
    "            break;\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load dataset\n",
    "'''\n",
    "def load_dataset():\n",
    "    x = np.arange(1,11).reshape(-1,1)\n",
    "    y = np.array([5.56, 5.7, 5.91, 6.40, 6.80, 7.05, 8.9, 8.7, 9.0, 9.05])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 value 6.4 cs (6.236666666666667, 8.912500000000001)\n",
      "new res:  1.9300083333333335\n",
      "index 0 value 3.7 cs (-0.513333333333334, 0.219999999999999)\n",
      "new res:  0.8006750000000016\n",
      "index 0 value 6.4 cs (0.1466666666666668, -0.2200000000000002)\n",
      "new res:  0.4780083333333344\n",
      "index 0 value 4.6 cs (-0.16083333333333316, 0.1072222222222227)\n",
      "new res:  0.30555925925925986\n",
      "index 0 value 6.4 cs (0.0714814814814817, -0.10722222222222255)\n",
      "new res:  0.22891522633744874\n",
      "index 0 value 2.8 cs (-0.1506481481481483, 0.0376620370370373)\n",
      "new res:  0.17217806498628246\n",
      "index 0 value 8.2 cs (-0.01870949074074102, 0.07483796296296319)\n",
      "new res:  0.1581762632351673\n",
      "index 0 value 6.4 cs (0.04381751543209855, -0.06572627314814783)\n",
      "new res:  0.1293766433555344\n",
      "index 0 value 5.5 cs (-0.041038580246913446, 0.04103858024691309)\n",
      "new res:  0.11253499266871056\n",
      "index 0 value 7.3 cs (0.022484209656084633, -0.052463155864198065)\n",
      "new res:  0.10073906671200575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "models = train(dataset, labels, 10, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
