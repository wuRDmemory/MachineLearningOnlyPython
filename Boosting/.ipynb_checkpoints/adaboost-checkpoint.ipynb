{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost算法\n",
    "\n",
    "生成单个结点：树桩\n",
    "1. 遍历所有的特征\n",
    "2. 以一定步长（或者自己生成一些切分点，比如相邻数据的中点）便利所有的切分点，得到误差$e_m=\\sum_{i=1}^{N}w_{mi}I(G(x)\\neq y_i)$\n",
    "3. 找到最小的使$e_m$最小的切分点和特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "give specific split point and get the stump label\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    index: index\n",
    "    value: split point value\n",
    "    label: all labbel\n",
    "return:\n",
    "    label: split label\n",
    "'''\n",
    "def subset_label(dataset, index, value, ope):\n",
    "    ret_label = np.ones(dataset.shape[0])\n",
    "    \n",
    "    if ope == 'lt':\n",
    "        ret_label[dataset[:, index] < value] = -1\n",
    "    else:\n",
    "        ret_label[dataset[:, index] >= value] = -1\n",
    "    \n",
    "    return ret_label\n",
    "\n",
    "'''\n",
    "stump generation\n",
    "parameter:\n",
    "    dataset: data\n",
    "    labels: labels\n",
    "    weight: weight D\n",
    "'''\n",
    "def generate_stump(dataset, labels, weight):\n",
    "    n, m = dataset.shape\n",
    "    \n",
    "    best_em = np.inf\n",
    "    best_index = 0\n",
    "    best_split_point = [0, 'lt']\n",
    "    max_num = 10; \n",
    "    for i in range(m):\n",
    "        min_value = dataset[:, i].min()\n",
    "        max_value = dataset[:, i].max()\n",
    "        stride =  (max_value - min_value) / max_num\n",
    "        for ope in ['lt', 'gt']:\n",
    "            for j in range(-1, max_num+1):\n",
    "                split_point = min_value + stride*j\n",
    "                sub_labels = subset_label(dataset, i, split_point, ope)\n",
    "                em = np.sum(weight[sub_labels != labels])\n",
    "                # print(\"split: {} {} Em {}\".format(ope, split_point, em))\n",
    "                \n",
    "                if em < best_em:\n",
    "                    best_em = em\n",
    "                    best_index = i\n",
    "                    best_split_point = [split_point, ope]\n",
    "    return best_em, best_index, best_split_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test function\n",
    "\n",
    "1. 加载简单的数据\n",
    "2. 测试是否可以找到最好的切分点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "load_dataset, generate the dataset and labels\n",
    "'''\n",
    "def load_dataset():\n",
    "    data = np.array([0,1,2,3,4,5,6,7,8,9]).reshape(-1, 1)\n",
    "    labels = np.array([1,1,1,-1,-1,-1,1,1,1,-1])\n",
    "    \n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004 0 [2.7, 'gt']\n"
     ]
    }
   ],
   "source": [
    "dataset, labels = load_dataset()\n",
    "D0 = np.ones_like(labels)/len(labels)\n",
    "\n",
    "best_em, best_index, best_split = generate_stump(dataset, labels, D0)\n",
    "print(best_em, best_index, best_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complete process\n",
    "\n",
    "1. 循环的进行子分类器的训练，得到一系列的子分类器\n",
    "2. 根据em，获取每个子分类器的权重\n",
    "3. 根据分类误差，计算下一个子分类器的weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "update weight\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    label: labels\n",
    "    weight: last weight\n",
    "    alpha: sub-classifier's weight\n",
    "    split_point: split point\n",
    "'''\n",
    "def update_weight(dataset, labels, weightk, alphak, Gx):\n",
    "    idx, value, ope = Gx\n",
    "    \n",
    "    res_labels = np.ones_like(labels)\n",
    "    if ope == 'lt':\n",
    "        res_labels[dataset[:, idx] < value] = -1\n",
    "    else:\n",
    "        res_labels[dataset[:, idx] >= value] = -1\n",
    "    '''\n",
    "    update weight\n",
    "    '''\n",
    "    weight = weightk*np.exp(-alphak*labels*res_labels)\n",
    "    weight = weight/weight.sum()\n",
    "    \n",
    "    return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pred_result\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    idx: feature index\n",
    "    value: model parameter\n",
    "    ope: operator\n",
    "'''\n",
    "def pred_result(dataset, idx, value, ope):\n",
    "    N = dataset.shape[0]\n",
    "    res = np.ones(N)\n",
    "    \n",
    "    if ope == 'lt':\n",
    "        res[dataset[:, idx] < value] = -1\n",
    "    else:\n",
    "        res[dataset[:, idx] >= value] = -1\n",
    "        \n",
    "    return res\n",
    "\n",
    "'''\n",
    "pred: predict the result\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    idx: feature index\n",
    "    value: model parameter\n",
    "    ope: operator\n",
    "'''\n",
    "def pred(dataset, labels, model):\n",
    "    add = np.zeros_like(labels)\n",
    "    for idx, value, ope, alpha in model:\n",
    "        res = pred_result(dataset, idx, value, ope)\n",
    "        add = add + alpha*res\n",
    "    \n",
    "    add[add >= 0] = 1\n",
    "    add[add < 0] = -1\n",
    "    add = add.astype(labels.dtype)\n",
    "    return np.sum(add != labels)\n",
    "    \n",
    "'''\n",
    "train adaboost\n",
    "parameter:\n",
    "    dataset: dataset\n",
    "    labels: label\n",
    "'''\n",
    "def train(dataset, labels, M, toler):\n",
    "    n, m = dataset.shape\n",
    "    last_weight = np.ones_like(labels)/n\n",
    "    \n",
    "    models = []\n",
    "    for i in range(M):\n",
    "        ''' generate stump '''\n",
    "        Em, idx, split = generate_stump(dataset, labels, last_weight)\n",
    "        value, ope = split\n",
    "        ''' update alpha '''\n",
    "        alpha = np.log((1-Em)/Em)/2.0\n",
    "        ''' update weight '''\n",
    "        last_weight = update_weight(dataset, labels, last_weight, alpha, [idx, value, ope])\n",
    "        models.append([idx, value, ope, alpha])\n",
    "        error_cnt = pred(dataset, labels, models)\n",
    "        print(\">>> alpha {} Em {} ErrorRate {}/{}={}\".format(alpha, Em, error_cnt, n, error_cnt/n))\n",
    "        if error_cnt < toler:\n",
    "            break\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> alpha 0.4236489301936017 Em 0.30000000000000004 ErrorRate 3/10=0.3\n",
      ">>> alpha 0.6496414920651304 Em 0.21428571428571427 ErrorRate 3/10=0.3\n",
      ">>> alpha 0.752038698388137 Em 0.18181818181818185 ErrorRate 0/10=0.0\n",
      "[0, 2.7, 'gt', 0.4236489301936017]\n",
      "[0, 8.1, 'gt', 0.6496414920651304]\n",
      "[0, 5.4, 'lt', 0.752038698388137]\n"
     ]
    }
   ],
   "source": [
    "models = train(dataset, labels, 4, 1)\n",
    "for m in models:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用更大的数据集进行验证\n",
    "\n",
    "1. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "load dataset\n",
    "parameter:\n",
    "    train_path: train_dataset file path\n",
    "    test_path: test dataset file path\n",
    "'''\n",
    "def load_dataset(train_path, test_path):\n",
    "    \n",
    "    def load(file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r') as fp:\n",
    "            for line in fp.readlines():\n",
    "                line = line.strip()\n",
    "                elem = [float(x) for x in line.split('\\t')]\n",
    "                data.append(elem)\n",
    "        return np.array(data)\n",
    "    \n",
    "    train_data = load(train_path)\n",
    "    test_data = load(test_path)\n",
    "    \n",
    "    return train_data[:, :-1], train_data[:, -1].astype(np.int64), test_data[:, :-1], test_data[:, -1].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_label, test_data, test_label = load_dataset('./horseColicTraining2.txt', './horseColicTest2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> alpha 0.4616623792657674 Em 0.28428093645484953 ErrorRate 85/299=0.2842809364548495\n",
      ">>> alpha 0.3124824504246708 Em 0.3486531061022541 ErrorRate 85/299=0.2842809364548495\n",
      ">>> alpha 0.28680973201695786 Em 0.3604020725787441 ErrorRate 74/299=0.24749163879598662\n",
      ">>> alpha 0.23297004638939492 Em 0.38557761823256775 ErrorRate 74/299=0.24749163879598662\n",
      ">>> alpha 0.19803846151213766 Em 0.40225526514026255 ErrorRate 76/299=0.25418060200668896\n",
      ">>> alpha 0.18847887349020642 Em 0.4068608605454535 ErrorRate 72/299=0.2408026755852843\n",
      ">>> alpha 0.15227368997476795 Em 0.42444621646246306 ErrorRate 72/299=0.2408026755852843\n",
      ">>> alpha 0.15510870821690512 Em 0.4230616708699977 ErrorRate 66/299=0.22073578595317725\n",
      ">>> alpha 0.1353619735335938 Em 0.4327293757248841 ErrorRate 74/299=0.24749163879598662\n",
      ">>> alpha 0.12521587326132078 Em 0.437717234434148 ErrorRate 69/299=0.23076923076923078\n",
      ">>> alpha 0.1334764812820768 Em 0.4336552906609674 ErrorRate 72/299=0.2408026755852843\n",
      ">>> alpha 0.14182243253771054 Em 0.42956041627172165 ErrorRate 64/299=0.2140468227424749\n",
      ">>> alpha 0.10421569100047721 Em 0.44807998475005917 ErrorRate 68/299=0.22742474916387959\n",
      ">>> alpha 0.11902115243796818 Em 0.4407688501719675 ErrorRate 65/299=0.21739130434782608\n",
      ">>> alpha 0.09880913594890822 Em 0.4507555895644719 ErrorRate 66/299=0.22073578595317725\n",
      ">>> alpha 0.11923265856486841 Em 0.4406645837887226 ErrorRate 65/299=0.21739130434782608\n",
      ">>> alpha 0.09876913235419935 Em 0.4507753974214658 ErrorRate 66/299=0.22073578595317725\n",
      ">>> alpha 0.09080272429069085 Em 0.4547230078080125 ErrorRate 68/299=0.22742474916387959\n",
      ">>> alpha 0.09441149728253792 Em 0.45293400971548964 ErrorRate 68/299=0.22742474916387959\n",
      ">>> alpha 0.10309268152640379 Em 0.4486354994677029 ErrorRate 65/299=0.21739130434782608\n",
      ">>> alpha 0.08582096324563357 Em 0.4571945575653842 ErrorRate 68/299=0.22742474916387959\n",
      ">>> alpha 0.09371382402961473 Em 0.453279778011655 ErrorRate 66/299=0.22073578595317725\n",
      ">>> alpha 0.09917908885798592 Em 0.4505724140729711 ErrorRate 66/299=0.22073578595317725\n",
      ">>> alpha 0.08877618625699078 Em 0.455728151073464 ErrorRate 68/299=0.22742474916387959\n",
      ">>> alpha 0.0789994419920271 Em 0.46058224581642093 ErrorRate 66/299=0.22073578595317725\n",
      ">>> alpha 0.08386232591460029 Em 0.45816686037847454 ErrorRate 66/299=0.22073578595317725\n",
      ">>> alpha 0.0740298200639928 Em 0.46305256107758497 ErrorRate 64/299=0.2140468227424749\n",
      ">>> alpha 0.0870768990895617 Em 0.45657125950657984 ErrorRate 62/299=0.20735785953177258\n",
      ">>> alpha 0.06670681329252913 Em 0.46669597744040436 ErrorRate 62/299=0.20735785953177258\n",
      ">>> alpha 0.07667756949662163 Em 0.4617361759505956 ErrorRate 62/299=0.20735785953177258\n",
      ">>> alpha 0.07897420181300305 Em 0.46059478749655797 ErrorRate 62/299=0.20735785953177258\n",
      ">>> alpha 0.09049344126780882 Em 0.45487638554606535 ErrorRate 62/299=0.20735785953177258\n",
      ">>> alpha 0.08606704344352138 Em 0.4570724218303546 ErrorRate 63/299=0.21070234113712374\n",
      ">>> alpha 0.06623384027008622 Em 0.4669314221479279 ErrorRate 63/299=0.21070234113712374\n",
      ">>> alpha 0.06961295881522134 Em 0.46524963547175546 ErrorRate 59/299=0.19732441471571907\n",
      ">>> alpha 0.056966979213487264 Em 0.47154728233777776 ErrorRate 58/299=0.1939799331103679\n",
      ">>> alpha 0.05645597701625721 Em 0.47180196344908976 ErrorRate 58/299=0.1939799331103679\n",
      ">>> alpha 0.06206234059737836 Em 0.46900860968614355 ErrorRate 58/299=0.1939799331103679\n",
      ">>> alpha 0.06666039216804033 Em 0.46671908509736587 ErrorRate 61/299=0.2040133779264214\n",
      ">>> alpha 0.06994741976558992 Em 0.46508321665317837 ErrorRate 58/299=0.1939799331103679\n",
      ">>> alpha 0.06636150810443597 Em 0.466867867985152 ErrorRate 61/299=0.2040133779264214\n",
      ">>> alpha 0.06539815404641558 Em 0.46734746045999526 ErrorRate 60/299=0.20066889632107024\n",
      ">>> alpha 0.05742861573915011 Em 0.47131721757729783 ErrorRate 58/299=0.1939799331103679\n",
      ">>> alpha 0.06387197024856604 Em 0.4681073731088142 ErrorRate 60/299=0.20066889632107024\n",
      ">>> alpha 0.049618562266470934 Em 0.47521105900030736 ErrorRate 57/299=0.19063545150501673\n",
      ">>> alpha 0.0648834886106153 Em 0.46760370430712317 ErrorRate 61/299=0.2040133779264214\n",
      ">>> alpha 0.04904972543372706 Em 0.4754947862967699 ErrorRate 60/299=0.20066889632107024\n",
      ">>> alpha 0.07449906242423895 Em 0.46281922914320084 ErrorRate 61/299=0.2040133779264214\n",
      ">>> alpha 0.06419804822502737 Em 0.4679450008371914 ErrorRate 61/299=0.2040133779264214\n",
      ">>> alpha 0.06608730231083315 Em 0.46700437134647127 ErrorRate 61/299=0.2040133779264214\n",
      ">>> alpha 0.05476656318183711 Em 0.4726440631925399 ErrorRate 57/299=0.19063545150501673\n",
      ">>> alpha 0.058114918838135646 Em 0.47097520879231863 ErrorRate 59/299=0.19732441471571907\n",
      ">>> alpha 0.04832549680883666 Em 0.4758560435622493 ErrorRate 58/299=0.1939799331103679\n",
      ">>> alpha 0.05447192623636934 Em 0.4727909430472346 ErrorRate 57/299=0.19063545150501673\n",
      ">>> alpha 0.06477808136599782 Em 0.46765618703365663 ErrorRate 55/299=0.18394648829431437\n",
      ">>> alpha 0.054811633196322596 Em 0.47262159569675954 ErrorRate 57/299=0.19063545150501673\n",
      ">>> alpha 0.044568399863065086 Em 0.4777305430374772 ErrorRate 56/299=0.18729096989966554\n",
      ">>> alpha 0.052967899268440574 Em 0.47354079037709407 ErrorRate 57/299=0.19063545150501673\n",
      ">>> alpha 0.056928015670955005 Em 0.4715667010656617 ErrorRate 56/299=0.18729096989966554\n",
      ">>> alpha 0.05533674732984575 Em 0.47235983340763626 ErrorRate 55/299=0.18394648829431437\n",
      ">>> alpha 0.05098384863403237 Em 0.4745301402436365 ErrorRate 59/299=0.19732441471571907\n",
      ">>> alpha 0.047512459218385025 Em 0.4762616303023633 ErrorRate 57/299=0.19063545150501673\n",
      ">>> alpha 0.04890732460463903 Em 0.4755658161815985 ErrorRate 58/299=0.1939799331103679\n",
      ">>> alpha 0.054906142537157976 Em 0.4725744829543525 ErrorRate 56/299=0.18729096989966554\n",
      ">>> alpha 0.04247471402261654 Em 0.47877540522704154 ErrorRate 55/299=0.18394648829431437\n",
      ">>> alpha 0.05416625906018185 Em 0.4729433265744436 ErrorRate 54/299=0.1806020066889632\n",
      ">>> alpha 0.047560633150230534 Em 0.4762375976844286 ErrorRate 52/299=0.17391304347826086\n",
      ">>> alpha 0.0536105817401535 Em 0.47322035995396267 ErrorRate 56/299=0.18729096989966554\n",
      ">>> alpha 0.04597353016698289 Em 0.477029415914502 ErrorRate 56/299=0.18729096989966554\n",
      ">>> alpha 0.054583692273715394 Em 0.47273522585579325 ErrorRate 56/299=0.18729096989966554\n",
      ">>> alpha 0.05568338631169966 Em 0.4721870468842934 ErrorRate 54/299=0.1806020066889632\n",
      ">>> alpha 0.04120937078741702 Em 0.4794069703984024 ErrorRate 56/299=0.18729096989966554\n",
      ">>> alpha 0.047617287304085626 Em 0.4762093346633647 ErrorRate 57/299=0.19063545150501673\n",
      ">>> alpha 0.04568155589993504 Em 0.4771750968788777 ErrorRate 55/299=0.18394648829431437\n",
      ">>> alpha 0.05450922510402785 Em 0.47277234887830394 ErrorRate 54/299=0.1806020066889632\n",
      ">>> alpha 0.04140271521532904 Em 0.4793104629383992 ErrorRate 53/299=0.17725752508361203\n",
      ">>> alpha 0.04725076259204261 Em 0.47639218529720057 ErrorRate 51/299=0.1705685618729097\n",
      ">>> alpha 0.04928510067917606 Em 0.47537738271882085 ErrorRate 53/299=0.17725752508361203\n",
      ">>> alpha 0.042609735363587004 Em 0.4787080165929587 ErrorRate 51/299=0.1705685618729097\n",
      ">>> alpha 0.04844150683299462 Em 0.4757981741262012 ErrorRate 53/299=0.17725752508361203\n",
      ">>> alpha 0.04424403880367279 Em 0.4778924041799288 ErrorRate 51/299=0.1705685618729097\n",
      ">>> alpha 0.040262171880003146 Em 0.4798797847931407 ErrorRate 53/299=0.17725752508361203\n",
      ">>> alpha 0.053873703108795516 Em 0.47308917851587184 ErrorRate 51/299=0.1705685618729097\n",
      ">>> alpha 0.04296342287036983 Em 0.47853149619301716 ErrorRate 51/299=0.1705685618729097\n",
      ">>> alpha 0.044335722530939155 Em 0.4778466521219661 ErrorRate 50/299=0.16722408026755853\n",
      ">>> alpha 0.0456721791465294 Em 0.4771797754874523 ErrorRate 49/299=0.16387959866220736\n",
      ">>> alpha 0.04172085314821166 Em 0.4791516684300288 ErrorRate 49/299=0.16387959866220736\n",
      ">>> alpha 0.04488986760590628 Em 0.4775701303185117 ErrorRate 49/299=0.16387959866220736\n",
      ">>> alpha 0.04304837501126245 Em 0.47848909858563726 ErrorRate 49/299=0.16387959866220736\n",
      ">>> alpha 0.046586725494859815 Em 0.4767234740098204 ErrorRate 49/299=0.16387959866220736\n",
      ">>> alpha 0.03498412191688543 Em 0.4825150716621826 ErrorRate 50/299=0.16722408026755853\n",
      ">>> alpha 0.046009521797301965 Em 0.47701145811084766 ErrorRate 50/299=0.16722408026755853\n",
      ">>> alpha 0.0364227114315368 Em 0.48179669315908435 ErrorRate 47/299=0.15719063545150502\n",
      ">>> alpha 0.04230550829765115 Em 0.4788598562465516 ErrorRate 51/299=0.1705685618729097\n",
      ">>> alpha 0.043845898804655434 Em 0.4780910884880463 ErrorRate 48/299=0.1605351170568562\n",
      ">>> alpha 0.036778996998280286 Em 0.481618788808706 ErrorRate 49/299=0.16387959866220736\n",
      ">>> alpha 0.045224308174450036 Em 0.47740324905763465 ErrorRate 51/299=0.1705685618729097\n",
      ">>> alpha 0.04036324499590513 Em 0.4798293302740275 ErrorRate 53/299=0.17725752508361203\n",
      ">>> alpha 0.045713649557823276 Em 0.47715908351346376 ErrorRate 50/299=0.16722408026755853\n",
      ">>> alpha 0.03653643973049759 Em 0.48173990461508437 ErrorRate 50/299=0.16722408026755853\n",
      "[9, 3.5, 'gt', 0.4616623792657674]\n",
      "[17, 52.5, 'gt', 0.3124824504246708]\n",
      "[3, 55.199999999999996, 'gt', 0.28680973201695786]\n",
      "[18, 62.300000000000004, 'lt', 0.23297004638939492]\n",
      "[10, 0.4, 'lt', 0.19803846151213766]\n",
      "[5, 2.4000000000000004, 'gt', 0.18847887349020642]\n",
      "[12, 1.2, 'lt', 0.15227368997476795]\n",
      "[7, 1.2, 'gt', 0.15510870821690512]\n",
      "[5, 0.4, 'lt', 0.1353619735335938]\n",
      "[4, 28.799999999999997, 'lt', 0.12521587326132078]\n",
      "[11, 2.4000000000000004, 'gt', 0.1334764812820768]\n",
      "[9, 4.5, 'lt', 0.14182243253771054]\n",
      "[14, 1.5, 'gt', 0.10421569100047721]\n",
      "[0, 1.1, 'lt', 0.11902115243796818]\n",
      "[4, 19.2, 'gt', 0.09880913594890822]\n",
      "[2, 36.72, 'lt', 0.11923265856486841]\n",
      "[3, 92.0, 'lt', 0.09876913235419935]\n",
      "[15, 0.4, 'lt', 0.09080272429069085]\n",
      "[18, 8.9, 'lt', 0.09441149728253792]\n",
      "[20, 1.01, 'gt', 0.10309268152640379]\n",
      "[16, 4.5, 'gt', 0.08582096324563357]\n",
      "[11, 3.2, 'lt', 0.09371382402961473]\n",
      "[3, 73.6, 'gt', 0.09917908885798592]\n",
      "[17, 37.5, 'lt', 0.08877618625699078]\n",
      "[4, 28.799999999999997, 'lt', 0.0789994419920271]\n",
      "[4, 19.2, 'gt', 0.08386232591460029]\n",
      "[13, 1.2, 'gt', 0.0740298200639928]\n",
      "[9, 2.5, 'lt', 0.0870768990895617]\n",
      "[5, 2.4000000000000004, 'gt', 0.06670681329252913]\n",
      "[3, 92.0, 'lt', 0.07667756949662163]\n",
      "[7, 4.2, 'gt', 0.07897420181300305]\n",
      "[7, 5.3999999999999995, 'lt', 0.09049344126780882]\n",
      "[17, 7.5, 'lt', 0.08606704344352138]\n",
      "[20, 2.02, 'lt', 0.06623384027008622]\n",
      "[17, 45.0, 'gt', 0.06961295881522134]\n",
      "[19, 1.2, 'gt', 0.056966979213487264]\n",
      "[4, 28.799999999999997, 'lt', 0.05645597701625721]\n",
      "[4, 19.2, 'gt', 0.06206234059737836]\n",
      "[3, 36.8, 'lt', 0.06666039216804033]\n",
      "[5, 3.2, 'lt', 0.06994741976558992]\n",
      "[17, 60.0, 'gt', 0.06636150810443597]\n",
      "[18, 8.9, 'lt', 0.06539815404641558]\n",
      "[12, 1.2, 'lt', 0.05742861573915011]\n",
      "[16, 4.5, 'gt', 0.06387197024856604]\n",
      "[20, 2.02, 'lt', 0.049618562266470934]\n",
      "[14, 0.75, 'gt', 0.0648834886106153]\n",
      "[7, 5.3999999999999995, 'lt', 0.04904972543372706]\n",
      "[7, 4.2, 'gt', 0.07449906242423895]\n",
      "[7, 5.3999999999999995, 'lt', 0.06419804822502737]\n",
      "[1, 1.8, 'gt', 0.06608730231083315]\n",
      "[11, 3.2, 'lt', 0.05476656318183711]\n",
      "[2, 36.72, 'lt', 0.058114918838135646]\n",
      "[11, 2.4000000000000004, 'gt', 0.04832549680883666]\n",
      "[3, 18.4, 'gt', 0.05447192623636934]\n",
      "[11, 0.4, 'lt', 0.06477808136599782]\n",
      "[9, 1.5, 'gt', 0.054811633196322596]\n",
      "[4, 28.799999999999997, 'lt', 0.044568399863065086]\n",
      "[7, 4.2, 'gt', 0.052967899268440574]\n",
      "[4, 19.2, 'gt', 0.056928015670955005]\n",
      "[7, 2.4, 'lt', 0.05533674732984575]\n",
      "[12, 0.3, 'gt', 0.05098384863403237]\n",
      "[4, 9.6, 'lt', 0.047512459218385025]\n",
      "[4, 86.39999999999999, 'lt', 0.04890732460463903]\n",
      "[17, 7.5, 'lt', 0.054906142537157976]\n",
      "[15, 2.4000000000000004, 'lt', 0.04247471402261654]\n",
      "[11, 1.2000000000000002, 'gt', 0.05416625906018185]\n",
      "[11, 0.4, 'lt', 0.047560633150230534]\n",
      "[3, 18.4, 'gt', 0.0536105817401535]\n",
      "[7, 4.2, 'gt', 0.04597353016698289]\n",
      "[3, 92.0, 'lt', 0.054583692273715394]\n",
      "[3, 73.6, 'gt', 0.05568338631169966]\n",
      "[5, 1.2000000000000002, 'gt', 0.04120937078741702]\n",
      "[6, 0.4, 'lt', 0.047617287304085626]\n",
      "[7, 5.3999999999999995, 'lt', 0.04568155589993504]\n",
      "[3, 36.8, 'lt', 0.05450922510402785]\n",
      "[11, 3.2, 'lt', 0.04140271521532904]\n",
      "[20, 1.01, 'gt', 0.04725076259204261]\n",
      "[19, 0.3, 'lt', 0.04928510067917606]\n",
      "[19, 1.2, 'gt', 0.042609735363587004]\n",
      "[20, 2.02, 'lt', 0.04844150683299462]\n",
      "[14, 1.5, 'gt', 0.04424403880367279]\n",
      "[4, 19.2, 'gt', 0.040262171880003146]\n",
      "[4, 28.799999999999997, 'lt', 0.053873703108795516]\n",
      "[7, 4.2, 'gt', 0.04296342287036983]\n",
      "[7, 5.3999999999999995, 'lt', 0.044335722530939155]\n",
      "[4, 67.2, 'gt', 0.0456721791465294]\n",
      "[4, 86.39999999999999, 'lt', 0.04172085314821166]\n",
      "[17, 60.0, 'gt', 0.04488986760590628]\n",
      "[12, 1.2, 'lt', 0.04304837501126245]\n",
      "[12, 0.3, 'gt', 0.046586725494859815]\n",
      "[4, 19.2, 'gt', 0.03498412191688543]\n",
      "[2, 36.72, 'lt', 0.046009521797301965]\n",
      "[3, 92.0, 'lt', 0.0364227114315368]\n",
      "[3, 110.39999999999999, 'gt', 0.04230550829765115]\n",
      "[18, 8.9, 'lt', 0.043845898804655434]\n",
      "[17, 37.5, 'lt', 0.036778996998280286]\n",
      "[17, 45.0, 'gt', 0.045224308174450036]\n",
      "[3, 18.4, 'gt', 0.04036324499590513]\n",
      "[4, 9.6, 'lt', 0.045713649557823276]\n",
      "[12, 1.2, 'lt', 0.03653643973049759]\n"
     ]
    }
   ],
   "source": [
    "model = train(train_data, train_label, 100, 0.01)\n",
    "\n",
    "for m in model:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test classifier\n",
    "\n",
    "使用验证集数据来验证分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuarcy 13/67=0.19402985074626866\n"
     ]
    }
   ],
   "source": [
    "N = test_data.shape[0]\n",
    "ErrorCnt = pred(test_data, test_label, model)\n",
    "\n",
    "print(\"accuarcy {}/{}={}\".format(ErrorCnt, N, ErrorCnt/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
